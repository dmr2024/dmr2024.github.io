<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>DMR 2024: Invited Speakers</title>
        <!-- Favicon-->
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Custom Google font-->
        <link rel="preconnect" href="https://fonts.googleapis.com" />
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
        <link href="https://fonts.googleapis.com/css2?family=Plus+Jakarta+Sans:wght@100;200;300;400;500;600;700;800;900&amp;display=swap" rel="stylesheet" />
        <!-- Bootstrap icons-->
        <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.8.1/font/bootstrap-icons.css" rel="stylesheet" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body class="d-flex flex-column h-100 bg-light">
        <main class="flex-shrink-0">
            <!-- Navigation-->
            <nav class="navbar navbar-expand-lg navbar-light bg-white py-3">
                <div class="container px-5">
                    <a class="navbar-brand" href="index.html"><span class="fw-bolder text-success">DMR 2024</span></a>
                    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                    <div class="collapse navbar-collapse" id="navbarSupportedContent">
                        <ul class="navbar-nav ms-auto mb-2 mb-lg-0 small fw-bolder">
                            <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
                            <li class="nav-item"><a class="nav-link" href="program.html">Workshop Program</a></li>
                            <li class="nav-item"><a class="nav-link" href="faq.html">FAQs</a></li>
                            <li class="nav-item"><a class="nav-link" href="call.html">Call for Papers</a></li>
                            <li class="nav-item"><a class="nav-link" href="committee.html">Committees</a></li>
                            <li class="nav-item"><a class="nav-link" href="invited.html">Invited Speakers</a></li>
                        </ul>
                    </div>
                </div>
            </nav>
            <!-- Page Content-->
            <div class="container px-5 my-5">
                <div class="text-center mb-5">
                    <h1 class="display-5 fw-bolder mb-0"><span class="text-gradient d-inline">Invited Speakers</span></h1>
                </div>
                <div class="row gx-5 justify-content-center">
                    <div class="col-lg-11 col-xl-9 col-xxl-8">

                        <div class="d-flex align-items-center justify-content-between mb-4 mt-5 border-top border-bottom p-2">
                            <h4 class="text-success fw-bolder mb-0">Fei Xia, University of Washington</h4>
                        </div>

                        <p><strong>BIO:</strong></p>
                            Fei Xia is a Full Professor at the Linguistics Department at the University of Washington (UW) and an adjunct faculty at the Department of Biomedical Informatics and Medical Education at the UW Medical School. 
                            Her research covers a wide range of NLP tasks such as grammar engineering, resource development, machine translation, information extraction, clinical NLP, and NLP for low-resourced languages. 
                            Her work is supported by grants from NSF, NIH, IARPA, Microsoft, IBM, and UW, and is in collaboration with researchers from both academia and industry. 
                            Fei Xia received her Bachelor's degree from Peking University, and M.S. and Ph.D. from the University of Pennsylvania. 
                            After graduation, she worked at IBM T. J. Watson Research Center before joining UW in 2005.
                        <p/>
                        <p><strong>ABSTRACT:</strong></p>
                            
                            <strong>If Data Could Talk</strong>
                            <p/>
                            During my first year of graduate study at the University of Pennsylvania, I took Dr. Martha Palmer's course on natural language processing (NLP). 
                            I was so intrigued by the topics that, by the end of that semester, I decided to switch my research focus from database to NLP and became Martha's student. 
                            Throughout the years, Martha has always been my role model, epitomizing the qualities of a great researcher, leader, and mentor.

                            One valuable lesson that I have learned from Martha is the importance of closely examining the data. 
                            Although it may sound simple, this step is often overlooked in many of recent studies. 
                            With the aid of numerous NLP packages, researchers can easily load, process, and evaluate NLP systems on benchmark datasets without delving into the specifics of the data itself. 
                            In this talk, I will underscore the importance of scrutinizing the data by describing two recent studies conducted by my team. 
                            One study pertains to the evaluation of Large Language Models (LLMs), while the other examines gender bias in educational materials and WordNet. 
                            In this context, the term "data" extends beyond just training and evaluation data. 
                            It encompasses a broader range of information, including lexical resources, instructions provided to Large Language Models (LLMs), system outputs, and any other relevant sources of information used in the research or analysis.

                        

                        <div class="d-flex align-items-center justify-content-between mb-4 mt-5 border-top border-bottom p-2">
                            <h4 class="text-success fw-bolder mb-0">Owen Rambow, Stony Brook University</h4>
                        </div>

                        <p><strong>BIO:</strong></p>
                        <p><strong>ABSTRACT:</strong></p>
                        
                            <strong>Propositional Content and Commitment to Truth</strong>
                            <p/>
                            Two of the things I have learned from Martha Palmer are relevant to this talk.  
                            First, data annotation is not a necessary evil that should be done as quickly as possible so that we can get to the real work (i.e., tweaking machine learning).  
                            Instead, it represents a conceptualization of what we think is an important aspect of language or language use.  
                            The development of a manual and annotation exercises help us refine the concepts we are defining.  
                            Second, how we represent propositional content (who-did-what-to-whom) matters.

                            In this talk, I will summarize work that goes beyond the lexical semantics of propositional content to pragmatics.  
                            We do not only communicate propositional content, we also signal to our discourse partners to what extent we are committed to the truth of that content.  
                            For example, we can include hedges, or we can talk about desires rather than factual content, or we can report what others said, leaving open our own commitment.  
                            This notion of commitment has been studied under different names (veridicality, factuality, factivity, belief, commitment) in various disciplines (linguistics, philosophy, psychology, NLP, AI).  
                            I will summarize past theoretical approaches, some annotation efforts, and some recent machine learning approaches.  
                            I will conclude by linking this notion back to the notion of propositional content: our commitment to the truth of a proposition can be different for different parts of a proposition.   
                            This will remain as future work.

                    </div>
                </div>
            </div>
        </main>
        <!-- Footer-->
        <footer class="bg-white py-4 mt-auto">
            <div class="container px-5">
                <div class="row align-items-center justify-content-between flex-column flex-sm-row">
                    <div class="col-auto"><div class="small m-0">Last updated: October 2023</div></div>
                    <div class="col-auto">Hosted by GitHub Pages</div>
                </div>
            </div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
